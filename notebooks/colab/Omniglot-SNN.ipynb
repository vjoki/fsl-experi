{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Omniglot-SNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX7ynANy2SlD"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjxJwoG5IiZ_"
      },
      "source": [
        "%%capture\n",
        "#!pip install pytorch-lightning Augmentor\n",
        "!pip install Augmentor\n",
        "!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN1o0Bb62Ny-"
      },
      "source": [
        "# The dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTBO4IQ_IvNs"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from random import Random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import Augmentor\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def copy_alphabets(write_dir, alphabets):\n",
        "    for alphabet in alphabets:\n",
        "        alpha_dir = os.path.basename(os.path.normpath(alphabet)) + '_'\n",
        "        for char in os.listdir(alphabet):\n",
        "            char = os.fsdecode(char)\n",
        "            dir_name = alpha_dir + char\n",
        "\n",
        "            val_path = os.path.join(write_dir, dir_name)\n",
        "            os.makedirs(val_path)\n",
        "\n",
        "            char_path = os.path.join(alphabet, char)\n",
        "            for drawer in os.listdir(char_path):\n",
        "                drawer_path = os.path.join(char_path, drawer)\n",
        "                shutil.copyfile(\n",
        "                    drawer_path, os.path.join(\n",
        "                        val_path, drawer\n",
        "                    )\n",
        "                )\n",
        "\n",
        "\n",
        "# adapted from https://github.com/kevinzakka/one-shot-siamese\n",
        "class Omniglot(dset.ImageFolder):\n",
        "    resources = [\n",
        "        (\"https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\", \"68d2efa1b9178cc56df9314c21c6e718\"),\n",
        "        (\"https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\", \"6b91aef0f799c5bb55b94e3f2daec811\")\n",
        "    ]\n",
        "\n",
        "    def __init__(self, data_path, mode, seed=0):\n",
        "        self.raw_path = os.path.join(data_path, 'raw')\n",
        "        self.processed_path = os.path.join(data_path, 'processed')\n",
        "        self._rng_seed = seed\n",
        "        self._download()\n",
        "        super().__init__(root=os.path.join(self.processed_path, mode))\n",
        "\n",
        "    def _processed_check_exists(self):\n",
        "        return (os.path.exists(os.path.join(self.processed_path, 'train')) and\n",
        "                os.path.exists(os.path.join(self.processed_path, 'valid')) and\n",
        "                os.path.exists(os.path.join(self.processed_path, 'test')))\n",
        "\n",
        "    def _raw_check_exists(self):\n",
        "        return (os.path.exists(os.path.join(self.raw_path, 'images_background')) and\n",
        "                os.path.exists(os.path.join(self.raw_path, 'images_evaluation')))\n",
        "\n",
        "    def _download(self):\n",
        "        if self._processed_check_exists():\n",
        "            return\n",
        "\n",
        "        if self._raw_check_exists():\n",
        "            self._process()\n",
        "            return\n",
        "\n",
        "        import shutil\n",
        "        os.makedirs(self.raw_path, exist_ok=True)\n",
        "        for (url, md5) in self.resources:\n",
        "            filename = url.rpartition('/')[2]\n",
        "            dset.utils.download_and_extract_archive(url, download_root=self.raw_path, filename=filename, md5=md5)\n",
        "\n",
        "        bg_path = os.path.join(self.raw_path, 'images_background')\n",
        "        eval_path = os.path.join(self.raw_path, 'images_evaluation')\n",
        "        for d in sorted(next(os.walk(eval_path))[1])[:10]:\n",
        "            shutil.move(os.path.join(eval_path, d), bg_path)\n",
        "\n",
        "        self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        np.random.seed(self._rng_seed)\n",
        "        os.makedirs(self.processed_path, exist_ok=True)\n",
        "\n",
        "        back_dir = os.path.join(self.raw_path, 'images_background')\n",
        "        eval_dir = os.path.join(self.raw_path, 'images_evaluation')\n",
        "        write_dir = self.processed_path\n",
        "\n",
        "        # get list of all alphabets\n",
        "        background_alphabets = [os.path.join(back_dir, x) for x in next(os.walk(back_dir))[1]]\n",
        "        background_alphabets.sort()\n",
        "\n",
        "        # list of all drawers (1 to 20)\n",
        "        background_drawers = list(np.arange(1, 21))\n",
        "        print(\"There are {} alphabets.\".format(len(background_alphabets)))\n",
        "\n",
        "        # from 40 alphabets, randomly select 30\n",
        "        train_alphabets = list(np.random.choice(background_alphabets, size=30, replace=False))\n",
        "\n",
        "        valid_alphabets = [x for x in background_alphabets if x not in train_alphabets]\n",
        "        test_alphabets = [os.path.join(eval_dir, x) for x in next(os.walk(eval_dir))[1]]\n",
        "\n",
        "        train_alphabets.sort()\n",
        "        valid_alphabets.sort()\n",
        "        test_alphabets.sort()\n",
        "\n",
        "        copy_alphabets(os.path.join(write_dir, 'train'), train_alphabets)\n",
        "        copy_alphabets(os.path.join(write_dir, 'valid'), valid_alphabets)\n",
        "        copy_alphabets(os.path.join(write_dir, 'test'), test_alphabets)\n",
        "\n",
        "\n",
        "# from https://github.com/kevinzakka/one-shot-siamese\n",
        "class OmniglotTrain(Dataset):\n",
        "    def __init__(self, dataset, num_train, augment=False):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.num_train = num_train\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_train\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image1 = random.choice(self.dataset.imgs)\n",
        "\n",
        "        # get image from same class\n",
        "        label = None\n",
        "        if index % 2 == 1:\n",
        "            label = 1.0\n",
        "            while True:\n",
        "                image2 = random.choice(self.dataset.imgs)\n",
        "                if image1[1] == image2[1]:\n",
        "                    break\n",
        "        # get image from different class\n",
        "        else:\n",
        "            label = 0.0\n",
        "            while True:\n",
        "                image2 = random.choice(self.dataset.imgs)\n",
        "                if image1[1] != image2[1]:\n",
        "                    break\n",
        "        image1 = Image.open(image1[0])\n",
        "        image2 = Image.open(image2[0])\n",
        "        image1 = image1.convert('L')\n",
        "        image2 = image2.convert('L')\n",
        "\n",
        "        # apply transformation on the fly\n",
        "        if self.augment:\n",
        "            p = Augmentor.Pipeline()\n",
        "            p.rotate(probability=0.5, max_left_rotation=15, max_right_rotation=15)\n",
        "            p.random_distortion(\n",
        "                probability=0.5, grid_width=6, grid_height=6, magnitude=10,\n",
        "            )\n",
        "            trans = transforms.Compose([\n",
        "                p.torch_transform(),\n",
        "                transforms.ToTensor(),\n",
        "            ])\n",
        "        else:\n",
        "            trans = transforms.ToTensor()\n",
        "\n",
        "        image1 = trans(image1)\n",
        "        image2 = transforms.ToTensor()(image2)\n",
        "        y = torch.from_numpy(np.array([label], dtype=np.float32))\n",
        "        return (image1, image2, y)\n",
        "\n",
        "\n",
        "# from https://github.com/kevinzakka/one-shot-siamese\n",
        "class OmniglotTest(Dataset):\n",
        "    def __init__(self, dataset, trials, way, seed=0):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.trials = trials\n",
        "        self.way = way\n",
        "        self.transform = transforms.ToTensor()\n",
        "        self.seed = seed\n",
        "        self.img1 = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.trials * self.way)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        self.rng = Random(self.seed + index)\n",
        "\n",
        "        idx = index % self.way\n",
        "        label = None\n",
        "        # generate image pair from same class\n",
        "        if idx == 0:\n",
        "            label = 1.0\n",
        "            self.img1 = self.rng.choice(self.dataset.imgs)\n",
        "            while True:\n",
        "                img2 = self.rng.choice(self.dataset.imgs)\n",
        "                if self.img1[1] == img2[1]:\n",
        "                    break\n",
        "        # generate image pair from different class\n",
        "        else:\n",
        "            label = 0.0\n",
        "            while True:\n",
        "                img2 = self.rng.choice(self.dataset.imgs)\n",
        "                if self.img1[1] != img2[1]:\n",
        "                    break\n",
        "\n",
        "        img1 = Image.open(self.img1[0])\n",
        "        img2 = Image.open(img2[0])\n",
        "        img1 = img1.convert('L')\n",
        "        img2 = img2.convert('L')\n",
        "        img1 = self.transform(img1)\n",
        "        img2 = self.transform(img2)\n",
        "        y = torch.from_numpy(np.array([label], dtype=np.float32))\n",
        "        return (img1, img2, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6NKumD42JIL"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiqqSbE2IxbF"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from typing_extensions import Final\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import DataLoader\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "\n",
        "class CNNLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 1-channel input\n",
        "            nn.Conv2d(1, 64, kernel_size=10),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=7),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=4),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.cnn(x)\n",
        "\n",
        "\n",
        "class TwinNet(pl.LightningModule):\n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parser):\n",
        "        parser = ArgumentParser(parents=[parser], add_help=False)\n",
        "        parser.add_argument('--learning_rate', type=float, default=1e-3, help='Initial learning rate used by auto_lr_find')\n",
        "        parser.add_argument('--batch_size', type=int, default=128)\n",
        "        parser.add_argument('--num_workers', type=int, default=1, help='number of workers used by DataLoader')\n",
        "        parser.add_argument('--trials', type=int, default=320)\n",
        "        parser.add_argument('--train_classes', type=int, default=20)\n",
        "        parser.add_argument('--num_train', type=int, default=50000)\n",
        "        parser.add_argument('--rng_seed', type=int, default=1)\n",
        "        parser.add_argument('--data_path', type=str, default='./data/')\n",
        "        return parser\n",
        "\n",
        "    def __init__(self, learning_rate, batch_size,\n",
        "                 num_workers, data_path, rng_seed,\n",
        "                 train_classes, trials, num_train, **kwargs):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.save_hyperparameters('learning_rate', 'batch_size')\n",
        "\n",
        "        # TODO: Not yet exactly clear on what these mean...\n",
        "        self._way: Final = train_classes\n",
        "        self._trials: Final = trials\n",
        "        self._num_train: Final = num_train\n",
        "\n",
        "        self._rng_seed: Final = rng_seed\n",
        "        self._data_path: Final = data_path\n",
        "\n",
        "        # TODO: Does this work right, what about TPUs?\n",
        "        self._num_workers: Final = num_workers\n",
        "        self._pin_memory: Final = False\n",
        "        if torch.cuda.is_available():\n",
        "            self._num_workers = num_workers\n",
        "            self._pin_memory = True\n",
        "\n",
        "        self.cnn: nn.Module = CNNLayer()\n",
        "        # 256*6*6 = 9216\n",
        "        self.fcl: nn.Module = nn.Sequential(nn.Linear(9216, 4096), nn.Sigmoid())\n",
        "        self.out: nn.Module = nn.Linear(4096, 1)\n",
        "\n",
        "        self.train_accuracy = pl.metrics.Accuracy()\n",
        "        self.val_accuracy = pl.metrics.Accuracy(compute_on_step=False)\n",
        "        self.test_accuracy = pl.metrics.Accuracy(compute_on_step=False)\n",
        "\n",
        "    # prediction/inference\n",
        "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
        "        # print(x1.shape)\n",
        "        x1 = self.cnn(x1)\n",
        "        # print('{0}::{1}'.format(x1.shape, x1.size()))\n",
        "        x1 = x1.view(x1.size()[0], -1)\n",
        "        # print(x1.shape)\n",
        "        x1 = self.fcl(x1)\n",
        "\n",
        "        x2 = self.cnn(x2)\n",
        "        x2 = x2.view(x2.size()[0], -1)\n",
        "        x2 = self.fcl(x2)\n",
        "\n",
        "        dist = torch.abs(x1 - x2)\n",
        "\n",
        "        return self.out(dist)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=(self.learning_rate or self.lr))\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "        return [optimizer], [{ 'scheduler': scheduler, 'monitor': 'val_loss', 'interval': 'epoch' }]\n",
        "\n",
        "    @staticmethod\n",
        "    def loss(x: torch.Tensor, y: torch.Tensor):\n",
        "        return F.binary_cross_entropy_with_logits(x, y)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x1, x2, y = batch\n",
        "        out = self.forward(x1, x2)\n",
        "        loss = self.loss(out, y)\n",
        "\n",
        "        acc = self.train_accuracy(out, y)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=False)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def train_epoch_end(self):\n",
        "        self.log('learning_rate_epoch', self.learning_rate or self.lr)\n",
        "        self.log('train_acc_epoch', self.train_accuracy.compute())\n",
        "\n",
        "        # Graph the model, requires input data for forward(),\n",
        "        # so we need to do it here as we need a dataloader().\n",
        "        if self.current_epoch == 1:\n",
        "            x, _ = next(iter(self.train_dataloader()))\n",
        "            self.logger.log_graph(TwinNet(batch_size=128, learning_rate=1e-3, rng_seed=0, train_classes=20, trials=320, num_train=50000, num_workers=4, data_path='./data/'), x)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x1, x2, y = batch\n",
        "        out = self.forward(x1, x2)\n",
        "        loss = self.loss(out, y)\n",
        "\n",
        "        self.val_accuracy(out, y)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log('val_acc_epoch', self.val_accuracy.compute())\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x1, x2, y = batch\n",
        "        out = self.forward(x1, x2)\n",
        "        loss = self.loss(out, y)\n",
        "\n",
        "        self.test_accuracy(out, y)\n",
        "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        self.log('test_acc_epoch', self.test_accuracy.compute())\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # TODO: Download and augment data here\n",
        "        #dset.ImageFolder(root=os.path.join(self._data_path, 'train'))\n",
        "        self._train_dataset = Omniglot(data_path=self._data_path, mode='train')\n",
        "        self._val_dataset = Omniglot(data_path=self._data_path, mode='valid')\n",
        "        self._test_dataset = Omniglot(data_path=self._data_path, mode='test')\n",
        "\n",
        "    def setup(self, stage):\n",
        "        if stage == 'fit':\n",
        "            self.training_set = OmniglotTrain(self._train_dataset, augment=True,\n",
        "                                              num_train=self._num_train)\n",
        "            self.validation_set = OmniglotTest(self._val_dataset, seed=self._rng_seed,\n",
        "                                               trials=self._trials, way=self._way)\n",
        "        if stage == 'test':\n",
        "            self.test_set = OmniglotTest(self._test_dataset, seed=self._rng_seed,\n",
        "                                         trials=self._trials, way=self._way)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.training_set, batch_size=self.batch_size,\n",
        "            shuffle=True, num_workers=self._num_workers, pin_memory=self._pin_memory,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.validation_set, batch_size=self._way, shuffle=False,\n",
        "            num_workers=self._num_workers, pin_memory=self._pin_memory,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_set, batch_size=self._way, shuffle=False,\n",
        "            num_workers=self._num_workers, pin_memory=self._pin_memory,\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q2iypUB2E0e"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKdWu-DJKzgk"
      },
      "source": [
        "    pl.seed_everything(0)\n",
        "    logger = TensorBoardLogger('./lightning_logs/', name='snn')\n",
        "    logger.log_hyperparams({'learning_rate': 0.001, 'rng_seed': 0, 'train_classes': 20, 'trials': 320, 'num_train': 50000, 'tpu_cores': 8, 'num_workers': 4, 'batch_size': 128, 'max_epochs': 5, 'profiler': True})\n",
        "\n",
        "    model = TwinNet(batch_size=128, learning_rate=1e-3, rng_seed=0, train_classes=20, trials=320, num_train=50000, num_workers=4, data_path='./data/')\n",
        "\n",
        "    # early_stop_callback = EarlyStopping(monitor='val_loss', min_delta=0.05, patience=7, verbose=False, mode='min')\n",
        "    # TODO: Is val_loss a good choice here?.\n",
        "    checkpoint_callback = ModelCheckpoint(monitor='val_loss', filepath='./snn-omniglot-{epoch}', save_top_k=3, mode='min')\n",
        "    trainer = pl.Trainer(progress_bar_refresh_rate=20, deterministic=True,\n",
        "                         gpus=1, \n",
        "                         max_epochs=50,\n",
        "                         logger=logger, checkpoint_callback=checkpoint_callback,\n",
        "                         auto_lr_find=True)\n",
        "\n",
        "    # Tune learning rate.\n",
        "    trainer.tune(model)\n",
        "    # Train model.\n",
        "    trainer.fit(model)\n",
        "    print('Best model saved to: ', checkpoint_callback.best_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad88EdcJ19BQ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkh0RxM12ruu"
      },
      "source": [
        "# Test using best checkpoint.\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbgZVd0Oj-7T"
      },
      "source": [
        "# Start tensorboard.\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

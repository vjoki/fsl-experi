{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "from audiomentations import Compose, Normalize, AddGaussianSNR, AddGaussianNoise, AddImpulseResponse, AddShortNoises, AddBackgroundNoise\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patches\n",
    "import librosa\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "plt.rcParams['figure.dpi'] = 160\n",
    "n_fft = 512\n",
    "\n",
    "if not os.path.exists(os.path.join(DATA_PATH, 'LibriSpeech')):\n",
    "    torchaudio.datasets.LIBRISPEECH(DATA_PATH, url='test-clean', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = os.path.join(DATA_PATH, \"LibriSpeech/test-clean/121/127105/121-127105-0036.flac\")\n",
    "signal, sample_rate = torchaudio.load(test_file_path)\n",
    "print(vars(torchaudio.info(test_file_path)))\n",
    "\n",
    "signals1 = []\n",
    "for i in range(1,5):\n",
    "    test_file_path = os.path.join(DATA_PATH, \"LibriSpeech/test-clean/121/127105/121-127105-00{:02d}.flac\".format(int(36/i)))\n",
    "    signal1, _ = torchaudio.load(test_file_path)\n",
    "    signals1.append(signal1)\n",
    "\n",
    "signals2 = []\n",
    "for i in range(1,5):\n",
    "    test_file_path = os.path.join(DATA_PATH, \"LibriSpeech/test-clean/260/123286/260-123286-00{:02d}.flac\".format(int(31/i)))\n",
    "    signal1, _ = torchaudio.load(test_file_path)\n",
    "    signals2.append(signal1)\n",
    "    \n",
    "signals3 = []\n",
    "for i in range(1,5):\n",
    "    test_file_path = os.path.join(DATA_PATH, \"LibriSpeech/test-clean/7127/75946/7127-75946-00{:02d}.flac\".format(int(29/i)))\n",
    "    signal1, _ = torchaudio.load(test_file_path)\n",
    "    signals3.append(signal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class PreEmphasis(torch.nn.Module):  # pylint: disable=abstract-method\n",
    "    def __init__(self, coef: float = 0.97):\n",
    "        super().__init__()\n",
    "        self.coef = coef\n",
    "        # make kernel\n",
    "        # In pytorch, the convolution operation uses cross-correlation. So, filter is flipped.\n",
    "        self.register_buffer(\n",
    "            'flipped_filter', torch.FloatTensor([-self.coef, 1.]).unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        assert len(input.size()) == 2, 'The number of dimensions of input tensor must be 2!'\n",
    "        # reflect padding to match lengths of in/out\n",
    "        input = input.unsqueeze(1)\n",
    "        input = F.pad(input, (1, 0), 'reflect')  # type: ignore\n",
    "        return F.conv1d(input, self.flipped_filter).squeeze(1)  # type: ignore\n",
    "\n",
    "n_mels = 128\n",
    "n_fft = 512\n",
    "\n",
    "for i, s in enumerate(signals1):\n",
    "    s = PreEmphasis()(s)\n",
    "    mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(s[:,5000:30000]) + 1e-6\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig('spkr1-mel{}.pdf'.format(i), bbox_inches='tight', transparent='True', pad_inches=0)\n",
    "    \n",
    "for i, s in enumerate(signals2):\n",
    "    s = PreEmphasis()(s)\n",
    "    mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(s[:,5000:30000]) + 1e-6\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig('spkr2-mel{}.pdf'.format(i), bbox_inches='tight', transparent='True', pad_inches=0)\n",
    "\n",
    "for i, s in enumerate(signals3):\n",
    "    s = PreEmphasis()(s)\n",
    "    mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(s[:,5000:30000]) + 1e-6\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig('spkr3-mel{}.pdf'.format(i), bbox_inches='tight', transparent='True', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(signal.t().detach())\n",
    "plt.axis('off')\n",
    "plt.savefig('waveform.pdf')\n",
    "IPython.display.Audio(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro = torchaudio.transforms.Spectrogram(n_fft=n_fft, win_length=400, hop_length=160,\n",
    "                                            window_fn=torch.hamming_window)(signal)\n",
    "print(spectro.shape)\n",
    "\n",
    "plt.imshow(spectro.log2()[0,:,:], cmap='viridis')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('time')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel-spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 128\n",
    "melfreqs = librosa.core.mel_frequencies(fmin=0.0, fmax=sample_rate // 2, n_mels=n_mels)\n",
    "mel_ticks = matplotlib.ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(int(melfreqs[x])))\n",
    "mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft)(signal)\n",
    "print(mel_spectro.shape)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True, dpi=300)\n",
    "\n",
    "axes[0].set_title('hann window')\n",
    "axes[0].imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "axes[0].set_yticks(np.arange(0, mel_spectro.size(1), 30))\n",
    "axes[0].yaxis.set_major_formatter(mel_ticks)\n",
    "\n",
    "mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, window_fn=torch.hamming_window)(signal)\n",
    "axes[1].set_title('hamming window')\n",
    "axes[1].imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "axes[1].set_yticks(np.arange(0, mel_spectro.size(1), 30))\n",
    "axes[1].yaxis.set_major_formatter(mel_ticks)\n",
    "\n",
    "plt.ylabel('frequency (Hz)')\n",
    "plt.xlabel('time')\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.savefig('melspectro.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 64\n",
    "melfreqs = librosa.core.mel_frequencies(fmin=0.0, fmax=sample_rate // 2, n_mels=n_mels)\n",
    "mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(signal)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=False, dpi=300)\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('time')\n",
    "\n",
    "axes[0].set_title('64 mels')\n",
    "axes[0].imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "mel_spectro_40 = torchaudio.transforms.MelSpectrogram(n_mels=40, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(signal)\n",
    "axes[1].set_title('40 mels')\n",
    "axes[1].imshow(mel_spectro_40.log2()[0,:,:], cmap='viridis')\n",
    "axes[1].invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 128\n",
    "mel_spectro = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(signal) + 1e-6\n",
    "plt.axis('off')\n",
    "plt.imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig('melspectrogram.pdf', bbox_inches='tight', transparent='True', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MelSpectrogram with pre-emphasis and instance normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class PreEmphasis(torch.nn.Module):  # pylint: disable=abstract-method\n",
    "    def __init__(self, coef: float = 0.97):\n",
    "        super().__init__()\n",
    "        self.coef = coef\n",
    "        # make kernel\n",
    "        # In pytorch, the convolution operation uses cross-correlation. So, filter is flipped.\n",
    "        self.register_buffer(\n",
    "            'flipped_filter', torch.FloatTensor([-self.coef, 1.]).unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        assert len(input.size()) == 2, 'The number of dimensions of input tensor must be 2!'\n",
    "        # reflect padding to match lengths of in/out\n",
    "        input = input.unsqueeze(1)\n",
    "        input = F.pad(input, (1, 0), 'reflect')  # type: ignore\n",
    "        return F.conv1d(input, self.flipped_filter).squeeze(1)  # type: ignore\n",
    "\n",
    "melfreqs = librosa.core.mel_frequencies(fmin=0.0, fmax=sample_rate // 2, n_mels=n_mels)\n",
    "\n",
    "x = signal\n",
    "x = PreEmphasis()(x)\n",
    "x = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(x)\n",
    "x = x+1e-6\n",
    "x = x.log()\n",
    "x = torch.nn.InstanceNorm1d(n_mels)(x)\n",
    "\n",
    "y = signal\n",
    "y = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(y)\n",
    "y = y+1e-6\n",
    "y = y.log()\n",
    "y = torch.nn.InstanceNorm1d(n_mels)(y)\n",
    "\n",
    "z = signal\n",
    "z = torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window)(z)\n",
    "z = z+1e-6\n",
    "z = z.log()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, dpi=300)\n",
    "\n",
    "axes[0].set_title('orig range [{:.4}, {:.4}]'.format(torch.min(z), torch.max(z)))\n",
    "axes[0].imshow(z[0,:,:], cmap='viridis')\n",
    "\n",
    "axes[1].set_title('instancenorm range [{:.4}, {:.4}]'.format(torch.min(y), torch.max(y)))\n",
    "axes[1].imshow(y[0,:,:], cmap='viridis')\n",
    "\n",
    "axes[2].set_title('preemph range [{:.4}, {:.4}]'.format(torch.min(x), torch.max(x)))\n",
    "axes[2].imshow(x[0,:,:], cmap='viridis')\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MelSpectrogram with SpecAugment (without time warping)\n",
    "https://arxiv.org/abs/1904.08779\n",
    "https://discuss.pytorch.org/t/does-sparse-image-warp-from-tf-exist-in-pytorch/43514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=0.25\n",
    "T=0.15\n",
    "\n",
    "mel_spectro_spec_aug = torch.nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, win_length=400, hop_length=160, window_fn=torch.hamming_window),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=int(F * n_mels)),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=int(F * n_mels)),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=int(T * (n_fft // 2 + 1))),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=int(T * (n_fft // 2 + 1)))\n",
    ")(signal)\n",
    "\n",
    "plt.imshow(mel_spectro_spec_aug.log2()[0,:,:], cmap='viridis')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('time')\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.savefig('melspectro-aug.pdf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel-frequency cepstral coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=n_mels, log_mels=True)(signal)\n",
    "print(mfcc.shape)\n",
    "\n",
    "plt.figure(dpi=190)\n",
    "ax = sns.heatmap(mfcc[0,:,:], xticklabels=50, yticklabels=5, cbar_kws={'label': 'amplitude'})\n",
    "ax.set(xlabel='time', ylabel='coefficients')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "#ax.get_figure().savefig('mfcc.pdf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons to signal augmented with gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment with gaussian noise\n",
    "augment = Compose([\n",
    "    #AddGaussianSNR(min_SNR=0.5, max_SNR=0.5, p=1.0),\n",
    "    AddShortNoises(os.path.join(DATA_PATH, 'RIRS_NOISES', 'pointsource_noises'), max_snr_in_db=80, p=1.0),\n",
    "    AddBackgroundNoise(os.path.join(DATA_PATH, 'RIRS_NOISES', 'pointsource_noises'), p=1.0),\n",
    "    AddImpulseResponse(os.path.join(DATA_PATH, 'RIRS_NOISES', 'simulated_rirs'), leave_length_unchanged=True, p=1.0),\n",
    "    #Normalize()\n",
    "])\n",
    "augmented_np = augment(samples=signal.t().numpy().flatten(), sample_rate=sample_rate)\n",
    "\n",
    "print(np.min(augmented_np), np.max(augmented_np))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "\n",
    "axes[0].set_title('original')\n",
    "axes[0].plot(signal.t().detach())\n",
    "\n",
    "axes[1].set_title('augmented')\n",
    "axes[1].plot(augmented_np)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented signal\n",
    "IPython.display.Audio(augmented_np, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original signal\n",
    "IPython.display.Audio(signal, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "augmented = torch.from_numpy(augmented_np).view(1,-1)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "\n",
    "axes[0].set(xlabel='time', ylabel='frequency')\n",
    "axes[0].set_title('original')\n",
    "axes[0].imshow(spectro.log2()[0,:,:], cmap='viridis')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "spectro_aug = torchaudio.transforms.Spectrogram(n_fft=n_fft)(augmented)\n",
    "axes[1].set_title('augmented')\n",
    "axes[1].imshow(spectro_aug.log2()[0,:,:], cmap='viridis')\n",
    "axes[1].invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel-spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectro_aug = torchaudio.transforms.MelSpectrogram(n_fft=n_fft, n_mels=n_mels, win_length=400, hop_length=160, window_fn=torch.hamming_window)(augmented)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True)\n",
    "\n",
    "axes[0].set_title('original')\n",
    "axes[0].imshow(mel_spectro.log2()[0,:,:], cmap='viridis')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "axes[1].set(xlabel='time', ylabel='frequency')\n",
    "axes[1].set_title('augmented')\n",
    "axes[1].imshow(mel_spectro_aug.log2()[0,:,:], cmap='viridis')\n",
    "axes[1].invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel-frequency cepstral coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_aug = torchaudio.transforms.MFCC(sample_rate=sample_rate, log_mels=True)(augmented)\n",
    "\n",
    "plt.figure(dpi=190)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "\n",
    "sns.heatmap(mfcc[0,:,:], ax=axes[0], xticklabels=50, yticklabels=5)\n",
    "axes[0].set(xlabel='time', ylabel='coefficients')\n",
    "axes[0].set_title('original')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "axes[1].set_title('augmented')\n",
    "sns.heatmap(mfcc_aug[0,:,:], ax=axes[1], xticklabels=50, yticklabels=5, cbar_kws={'label': 'amplitude'})\n",
    "axes[1].invert_yaxis()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
